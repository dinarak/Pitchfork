{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset we used for Logistic Regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10986 entries, 0 to 10985\n",
      "Data columns (total 32 columns):\n",
      "reviewid              10986 non-null int64\n",
      "Unnamed: 0            10986 non-null int64\n",
      "Unnamed: 0.1          10986 non-null int64\n",
      "content               10986 non-null object\n",
      "genre                 9674 non-null object\n",
      "label                 10964 non-null object\n",
      "title                 10986 non-null object\n",
      "artist                10986 non-null object\n",
      "url                   10986 non-null object\n",
      "score                 10986 non-null float64\n",
      "best_new_music        10986 non-null int64\n",
      "author                10986 non-null object\n",
      "author_type           8561 non-null object\n",
      "pub_date              10986 non-null object\n",
      "pub_weekday           10986 non-null int64\n",
      "pub_day               10986 non-null int64\n",
      "pub_month             10986 non-null int64\n",
      "pub_year              10986 non-null int64\n",
      "year                  10705 non-null float64\n",
      "content_words         10986 non-null int64\n",
      "subjectivity          10986 non-null float64\n",
      "polarity              10986 non-null float64\n",
      "score_bin             10986 non-null int64\n",
      "genre_experimental    10986 non-null int64\n",
      "genre_folk/country    10986 non-null int64\n",
      "genre_global          10986 non-null int64\n",
      "genre_jazz            10986 non-null int64\n",
      "genre_metal           10986 non-null int64\n",
      "genre_pop/r&b         10986 non-null int64\n",
      "genre_rap             10986 non-null int64\n",
      "genre_rock            10986 non-null int64\n",
      "sum_genres            0 non-null float64\n",
      "dtypes: float64(5), int64(18), object(9)\n",
      "memory usage: 2.7+ MB\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('pf_readyforlogistic1.csv', encoding=\"ISO-8859-1\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['reviewid', 'Unnamed: 0', 'Unnamed: 0.1', 'content', 'genre', 'label',\n",
       "       'title', 'artist', 'url', 'score', 'best_new_music', 'author',\n",
       "       'author_type', 'pub_date', 'pub_weekday', 'pub_day', 'pub_month',\n",
       "       'pub_year', 'year', 'content_words', 'subjectivity', 'polarity',\n",
       "       'score_bin', 'genre_experimental', 'genre_folk/country', 'genre_global',\n",
       "       'genre_jazz', 'genre_metal', 'genre_pop/r&b', 'genre_rap', 'genre_rock',\n",
       "       'sum_genres'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.drop(['reviewid', 'Unnamed: 0', 'Unnamed: 0.1', 'content', 'genre', 'url', 'score', 'best_new_music', 'content_words', 'subjectivity', 'polarity', 'sum_genres'], axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1706"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(df.pub_year != df.year)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try a neural net on the currently numeric variables, to build a quick model without preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10986 entries, 0 to 10985\n",
      "Data columns (total 14 columns):\n",
      "pub_weekday           10986 non-null int64\n",
      "pub_day               10986 non-null int64\n",
      "pub_month             10986 non-null int64\n",
      "pub_year              10986 non-null int64\n",
      "year                  10705 non-null float64\n",
      "score_bin             10986 non-null int64\n",
      "genre_experimental    10986 non-null int64\n",
      "genre_folk/country    10986 non-null int64\n",
      "genre_global          10986 non-null int64\n",
      "genre_jazz            10986 non-null int64\n",
      "genre_metal           10986 non-null int64\n",
      "genre_pop/r&b         10986 non-null int64\n",
      "genre_rap             10986 non-null int64\n",
      "genre_rock            10986 non-null int64\n",
      "dtypes: float64(1), int64(13)\n",
      "memory usage: 1.2 MB\n"
     ]
    }
   ],
   "source": [
    "df1 = df.select_dtypes(include=[np.number])\n",
    "df1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10986 entries, 0 to 10985\n",
      "Data columns (total 14 columns):\n",
      "pub_weekday           10986 non-null int64\n",
      "pub_day               10986 non-null int64\n",
      "pub_month             10986 non-null int64\n",
      "pub_year              10986 non-null int64\n",
      "year                  10986 non-null float64\n",
      "score_bin             10986 non-null int64\n",
      "genre_experimental    10986 non-null int64\n",
      "genre_folk/country    10986 non-null int64\n",
      "genre_global          10986 non-null int64\n",
      "genre_jazz            10986 non-null int64\n",
      "genre_metal           10986 non-null int64\n",
      "genre_pop/r&b         10986 non-null int64\n",
      "genre_rap             10986 non-null int64\n",
      "genre_rock            10986 non-null int64\n",
      "dtypes: float64(1), int64(13)\n",
      "memory usage: 1.2 MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dinara\\Anaconda3\\lib\\site-packages\\pandas\\core\\generic.py:3295: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  self._update_inplace(new_data)\n"
     ]
    }
   ],
   "source": [
    "df1['year'].fillna(df1['pub_year'], inplace = True)\n",
    "df1.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.datasets import mnist\n",
    "from keras.utils import np_utils\n",
    "\n",
    "def build_logistic_model(input_dim, output_dim):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(output_dim, input_dim=input_dim, activation='softmax'))\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = df1.drop('score_bin', axis = 1)\n",
    "y = df1['score_bin']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10986, 13)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8788 train samples\n",
      "2198 test samples\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_1 (Dense)              (None, 1)                 14        \n",
      "=================================================================\n",
      "Total params: 14\n",
      "Trainable params: 14\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 8788 samples, validate on 2198 samples\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dinara\\Anaconda3\\lib\\site-packages\\keras\\models.py:942: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8788/8788 [==============================] - 0s 35us/step - loss: 10.3912 - acc: 0.3482 - mean_absolute_error: 0.6518 - val_loss: 10.3937 - val_acc: 0.3480 - val_mean_absolute_error: 0.6520\n",
      "Epoch 2/10\n",
      "8788/8788 [==============================] - 0s 15us/step - loss: 10.3912 - acc: 0.3482 - mean_absolute_error: 0.6518 - val_loss: 10.3937 - val_acc: 0.3480 - val_mean_absolute_error: 0.6520\n",
      "Epoch 3/10\n",
      "8788/8788 [==============================] - 0s 14us/step - loss: 10.3912 - acc: 0.3482 - mean_absolute_error: 0.6518 - val_loss: 10.3937 - val_acc: 0.3480 - val_mean_absolute_error: 0.6520\n",
      "Epoch 4/10\n",
      "8788/8788 [==============================] - 0s 15us/step - loss: 10.3912 - acc: 0.3482 - mean_absolute_error: 0.6518 - val_loss: 10.3937 - val_acc: 0.3480 - val_mean_absolute_error: 0.6520\n",
      "Epoch 5/10\n",
      "8788/8788 [==============================] - 0s 15us/step - loss: 10.3912 - acc: 0.3482 - mean_absolute_error: 0.6518 - val_loss: 10.3937 - val_acc: 0.3480 - val_mean_absolute_error: 0.6520\n",
      "Epoch 6/10\n",
      "8788/8788 [==============================] - 0s 16us/step - loss: 10.3912 - acc: 0.3482 - mean_absolute_error: 0.6518 - val_loss: 10.3937 - val_acc: 0.3480 - val_mean_absolute_error: 0.6520\n",
      "Epoch 7/10\n",
      "8788/8788 [==============================] - 0s 17us/step - loss: 10.3912 - acc: 0.3482 - mean_absolute_error: 0.6518 - val_loss: 10.3937 - val_acc: 0.3480 - val_mean_absolute_error: 0.6520\n",
      "Epoch 8/10\n",
      "8788/8788 [==============================] - 0s 19us/step - loss: 10.3912 - acc: 0.3482 - mean_absolute_error: 0.6518 - val_loss: 10.3937 - val_acc: 0.3480 - val_mean_absolute_error: 0.6520\n",
      "Epoch 9/10\n",
      "8788/8788 [==============================] - 0s 17us/step - loss: 10.3912 - acc: 0.3482 - mean_absolute_error: 0.6518 - val_loss: 10.3937 - val_acc: 0.3480 - val_mean_absolute_error: 0.6520\n",
      "Epoch 10/10\n",
      "8788/8788 [==============================] - 0s 19us/step - loss: 10.3912 - acc: 0.3482 - mean_absolute_error: 0.6518 - val_loss: 10.3937 - val_acc: 0.3480 - val_mean_absolute_error: 0.6520\n",
      "Test score: 10.393739137137555\n",
      "Test accuracy: 0.3480436760420361\n",
      "[10.393739137137555, 0.3480436760420361, 0.6519563236596695]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42, stratify = y)\n",
    "batch_size = 128\n",
    "nb_classes = 1\n",
    "nb_epoch = 10\n",
    "input_dim = 13\n",
    "\n",
    "# the data, shuffled and split between train and test sets\n",
    "\n",
    "X_train = X_train.astype('int64')\n",
    "X_test = X_test.astype('int64')\n",
    "print(X_train.shape[0], 'train samples')\n",
    "print(X_test.shape[0], 'test samples')\n",
    "\n",
    "model = build_logistic_model(input_dim, nb_classes)\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# compile the model\n",
    "model.compile(optimizer='sgd', loss='binary_crossentropy', metrics=['accuracy', 'mae'])\n",
    "history = model.fit(X_train, y_train,\n",
    "                    batch_size=batch_size, nb_epoch=nb_epoch,\n",
    "                    verbose=1, validation_data=(X_test, y_test))\n",
    "score = model.evaluate(X_test, y_test, verbose=0)\n",
    "\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try making y vector into a matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7690 train samples\n",
      "3296 test samples\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_2 (Dense)              (None, 2)                 28        \n",
      "=================================================================\n",
      "Total params: 28\n",
      "Trainable params: 28\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dinara\\Anaconda3\\lib\\site-packages\\keras\\models.py:942: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7690 samples, validate on 3296 samples\n",
      "Epoch 1/10\n",
      "7690/7690 [==============================] - 1s 70us/step - loss: 5.5804 - acc: 0.6519 - val_loss: 5.5833 - val_acc: 0.6517\n",
      "Epoch 2/10\n",
      "7690/7690 [==============================] - 1s 66us/step - loss: 5.5804 - acc: 0.6519 - val_loss: 5.5833 - val_acc: 0.6517\n",
      "Epoch 3/10\n",
      "7690/7690 [==============================] - 0s 51us/step - loss: 5.5804 - acc: 0.6519 - val_loss: 5.5833 - val_acc: 0.6517\n",
      "Epoch 4/10\n",
      "7690/7690 [==============================] - 0s 52us/step - loss: 5.5804 - acc: 0.6519 - val_loss: 5.5833 - val_acc: 0.6517\n",
      "Epoch 5/10\n",
      "7690/7690 [==============================] - 0s 61us/step - loss: 5.5804 - acc: 0.6519 - val_loss: 5.5833 - val_acc: 0.6517\n",
      "Epoch 6/10\n",
      "7690/7690 [==============================] - 0s 57us/step - loss: 5.5804 - acc: 0.6519 - val_loss: 5.5833 - val_acc: 0.6517\n",
      "Epoch 7/10\n",
      "7690/7690 [==============================] - 0s 61us/step - loss: 5.5804 - acc: 0.6519 - val_loss: 5.5833 - val_acc: 0.6517\n",
      "Epoch 8/10\n",
      "7690/7690 [==============================] - 0s 60us/step - loss: 5.5804 - acc: 0.6519 - val_loss: 5.5833 - val_acc: 0.6517\n",
      "Epoch 9/10\n",
      "7690/7690 [==============================] - 0s 63us/step - loss: 5.5804 - acc: 0.6519 - val_loss: 5.5833 - val_acc: 0.6517\n",
      "Epoch 10/10\n",
      "7690/7690 [==============================] - 0s 59us/step - loss: 5.5804 - acc: 0.6519 - val_loss: 5.5833 - val_acc: 0.6517\n",
      "Test score: 5.583347915445716\n",
      "Test accuracy: 0.6516990291262136\n",
      "[5.583347915445716, 0.6516990291262136]\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42, stratify = y)\n",
    "batch_size = 32\n",
    "nb_classes = 2\n",
    "nb_epoch = 10\n",
    "input_dim = 13\n",
    "\n",
    "# the data, shuffled and split between train and test sets\n",
    "\n",
    "X_train = X_train.astype('int64')\n",
    "X_test = X_test.astype('int64')\n",
    "print(X_train.shape[0], 'train samples')\n",
    "print(X_test.shape[0], 'test samples')\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "Y_train = np_utils.to_categorical(y_train, nb_classes)\n",
    "Y_test = np_utils.to_categorical(y_test, nb_classes)\n",
    "\n",
    "model = build_logistic_model(input_dim, nb_classes)\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# compile the model\n",
    "model.compile(optimizer='sgd', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "history = model.fit(X_train, Y_train,\n",
    "                    batch_size=batch_size, nb_epoch=nb_epoch,\n",
    "                    verbose=1, validation_data=(X_test, Y_test))\n",
    "score = model.evaluate(X_test, Y_test, verbose=0)\n",
    "\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's try adding more independent variables. \n",
    "## Add label and author variables. \n",
    "## The high rank music labels are the ones that most often receive high scores, high rank authors on average give high scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 10964 entries, 0 to 10985\n",
      "Data columns (total 20 columns):\n",
      "label                 10964 non-null object\n",
      "title                 10964 non-null object\n",
      "artist                10964 non-null object\n",
      "author                10964 non-null object\n",
      "author_type           8541 non-null object\n",
      "pub_date              10964 non-null object\n",
      "pub_weekday           10964 non-null int64\n",
      "pub_day               10964 non-null int64\n",
      "pub_month             10964 non-null int64\n",
      "pub_year              10964 non-null int64\n",
      "year                  10683 non-null float64\n",
      "score_bin             10964 non-null int64\n",
      "genre_experimental    10964 non-null int64\n",
      "genre_folk/country    10964 non-null int64\n",
      "genre_global          10964 non-null int64\n",
      "genre_jazz            10964 non-null int64\n",
      "genre_metal           10964 non-null int64\n",
      "genre_pop/r&b         10964 non-null int64\n",
      "genre_rap             10964 non-null int64\n",
      "genre_rock            10964 non-null int64\n",
      "dtypes: float64(1), int64(13), object(6)\n",
      "memory usage: 1.8+ MB\n"
     ]
    }
   ],
   "source": [
    "high_rank_labels = ['rhino', 'light in the attic', 'profound lore', 'matador', 'emi',\n",
    "       'editions mego', 'epitaph', 'constellation', 'relapse', '4ad']\n",
    "high_rank_authors = ['jenn pelly', 'seth colter walls', 'mark richardson',\n",
    "       'grayson haver currin', 'david drake', 'philip sherburne',\n",
    "       \"andy o'connor\", 'andy beta', 'amanda petrusich', 'marc masters']\n",
    "df.dropna(subset = ['label'], inplace = True)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df.drop(['title', 'artist', 'author_type'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2['is_author_kind'] = df2['author'].isin(high_rank_authors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 10964 entries, 0 to 10985\n",
      "Data columns (total 19 columns):\n",
      "label                 10964 non-null object\n",
      "author                10964 non-null object\n",
      "pub_date              10964 non-null object\n",
      "pub_weekday           10964 non-null int64\n",
      "pub_day               10964 non-null int64\n",
      "pub_month             10964 non-null int64\n",
      "pub_year              10964 non-null int64\n",
      "year                  10964 non-null float64\n",
      "score_bin             10964 non-null int64\n",
      "genre_experimental    10964 non-null int64\n",
      "genre_folk/country    10964 non-null int64\n",
      "genre_global          10964 non-null int64\n",
      "genre_jazz            10964 non-null int64\n",
      "genre_metal           10964 non-null int64\n",
      "genre_pop/r&b         10964 non-null int64\n",
      "genre_rap             10964 non-null int64\n",
      "genre_rock            10964 non-null int64\n",
      "is_author_kind        10964 non-null bool\n",
      "is_label_favored      10964 non-null bool\n",
      "dtypes: bool(2), float64(1), int64(13), object(3)\n",
      "memory usage: 1.5+ MB\n"
     ]
    }
   ],
   "source": [
    "df2['is_label_favored'] = df2['label'].isin(high_rank_labels)\n",
    "df2['year'].fillna(df2['pub_year'], inplace = True)\n",
    "df2.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = df2.drop(['label', 'author', 'pub_date', 'score_bin'], axis = 1)\n",
    "y = df2['score_bin']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10964, 15)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8771 train samples\n",
      "2193 test samples\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_3 (Dense)              (None, 2)                 32        \n",
      "=================================================================\n",
      "Total params: 32\n",
      "Trainable params: 32\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 8771 samples, validate on 2193 samples\n",
      "Epoch 1/10\n",
      "8771/8771 [==============================] - 1s 65us/step - loss: 10.4632 - acc: 0.3473 - val_loss: 10.4602 - val_acc: 0.3475\n",
      "Epoch 2/10\n",
      "8771/8771 [==============================] - 1s 62us/step - loss: 10.4632 - acc: 0.3473 - val_loss: 10.4602 - val_acc: 0.3475\n",
      "Epoch 3/10\n",
      "8771/8771 [==============================] - 0s 54us/step - loss: 10.4632 - acc: 0.3473 - val_loss: 10.4602 - val_acc: 0.3475\n",
      "Epoch 4/10\n",
      "8771/8771 [==============================] - 0s 49us/step - loss: 10.4632 - acc: 0.3473 - val_loss: 10.4602 - val_acc: 0.3475\n",
      "Epoch 5/10\n",
      "8771/8771 [==============================] - 0s 49us/step - loss: 10.4632 - acc: 0.3473 - val_loss: 10.4602 - val_acc: 0.3475\n",
      "Epoch 6/10\n",
      "8771/8771 [==============================] - 0s 49us/step - loss: 10.4632 - acc: 0.3473 - val_loss: 10.4602 - val_acc: 0.3475\n",
      "Epoch 7/10\n",
      "8771/8771 [==============================] - 0s 51us/step - loss: 10.4632 - acc: 0.3473 - val_loss: 10.4602 - val_acc: 0.3475\n",
      "Epoch 8/10\n",
      "8771/8771 [==============================] - 0s 49us/step - loss: 10.4632 - acc: 0.3473 - val_loss: 10.4602 - val_acc: 0.3475\n",
      "Epoch 9/10\n",
      "8771/8771 [==============================] - 0s 49us/step - loss: 10.4632 - acc: 0.3473 - val_loss: 10.4602 - val_acc: 0.3475\n",
      "Epoch 10/10\n",
      "8771/8771 [==============================] - 0s 54us/step - loss: 10.4632 - acc: 0.3473 - val_loss: 10.4602 - val_acc: 0.3475\n",
      "Test score: 10.460224631275155\n",
      "Test accuracy: 0.3474692202870073\n",
      "[10.460224631275155, 0.3474692202870073]\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42, stratify = y)\n",
    "batch_size = 32\n",
    "nb_classes = 2\n",
    "nb_epoch = 10\n",
    "input_dim = 15\n",
    "\n",
    "# the data, shuffled and split between train and test sets\n",
    "\n",
    "X_train = X_train.astype('int64')\n",
    "X_test = X_test.astype('int64')\n",
    "print(X_train.shape[0], 'train samples')\n",
    "print(X_test.shape[0], 'test samples')\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "Y_train = np_utils.to_categorical(y_train, nb_classes)\n",
    "Y_test = np_utils.to_categorical(y_test, nb_classes)\n",
    "\n",
    "model = build_logistic_model(input_dim, nb_classes)\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# compile the model\n",
    "model.compile(optimizer='sgd', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "history = model.fit(X_train, Y_train,\n",
    "                    batch_size=batch_size, epochs=nb_epoch,\n",
    "                    verbose=1, validation_data=(X_test, Y_test))\n",
    "score = model.evaluate(X_test, Y_test, verbose=0)\n",
    "\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try a model with two hidden layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8771 train samples\n",
      "2193 test samples\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_4 (Dense)              (None, 64)                1024      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 1,154\n",
      "Trainable params: 1,154\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 8771 samples, validate on 2193 samples\n",
      "Epoch 1/10\n",
      "8771/8771 [==============================] - 1s 70us/step - loss: 0.6540 - acc: 0.6477 - val_loss: 0.6465 - val_acc: 0.6525\n",
      "Epoch 2/10\n",
      "8771/8771 [==============================] - 1s 57us/step - loss: 0.6487 - acc: 0.6527 - val_loss: 0.6630 - val_acc: 0.6525\n",
      "Epoch 3/10\n",
      "8771/8771 [==============================] - 0s 56us/step - loss: 0.6494 - acc: 0.6527 - val_loss: 0.6461 - val_acc: 0.6525\n",
      "Epoch 4/10\n",
      "8771/8771 [==============================] - 0s 55us/step - loss: 0.6479 - acc: 0.6527 - val_loss: 0.6583 - val_acc: 0.6525\n",
      "Epoch 5/10\n",
      "8771/8771 [==============================] - 0s 52us/step - loss: 0.6484 - acc: 0.6527 - val_loss: 0.6728 - val_acc: 0.6525\n",
      "Epoch 6/10\n",
      "8771/8771 [==============================] - 1s 61us/step - loss: 0.6482 - acc: 0.6527 - val_loss: 0.6621 - val_acc: 0.6525\n",
      "Epoch 7/10\n",
      "8771/8771 [==============================] - 0s 51us/step - loss: 0.6487 - acc: 0.6527 - val_loss: 0.6595 - val_acc: 0.6525\n",
      "Epoch 8/10\n",
      "8771/8771 [==============================] - 0s 51us/step - loss: 0.6484 - acc: 0.6527 - val_loss: 0.6615 - val_acc: 0.6525\n",
      "Epoch 9/10\n",
      "8771/8771 [==============================] - 0s 51us/step - loss: 0.6483 - acc: 0.6527 - val_loss: 0.6623 - val_acc: 0.6525\n",
      "Epoch 10/10\n",
      "8771/8771 [==============================] - 0s 53us/step - loss: 0.6489 - acc: 0.6527 - val_loss: 0.6773 - val_acc: 0.6525\n",
      "Test score: 0.6773259057826883\n",
      "Test accuracy: 0.6525307799440184\n",
      "[0.6773259057826883, 0.6525307799440184]\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42, stratify = y)\n",
    "batch_size = 32\n",
    "nb_classes = 2\n",
    "nb_epoch = 10\n",
    "input_dim = 15\n",
    "\n",
    "# the data, shuffled and split between train and test sets\n",
    "\n",
    "X_train = X_train.astype('int64')\n",
    "X_test = X_test.astype('int64')\n",
    "print(X_train.shape[0], 'train samples')\n",
    "print(X_test.shape[0], 'test samples')\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "Y_train = np_utils.to_categorical(y_train, nb_classes)\n",
    "Y_test = np_utils.to_categorical(y_test, nb_classes)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(64, input_dim=input_dim, activation='tanh'))\n",
    "model.add(Dense(nb_classes, input_dim=64, activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# compile the model\n",
    "model.compile(optimizer='sgd', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "history = model.fit(X_train, Y_train,\n",
    "                    batch_size=batch_size, epochs=nb_epoch,\n",
    "                    verbose=1, validation_data=(X_test, Y_test))\n",
    "score = model.evaluate(X_test, Y_test, verbose=0)\n",
    "\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try ReLu as activation function for first layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8771 train samples\n",
      "2193 test samples\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_6 (Dense)              (None, 64)                1024      \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 1,154\n",
      "Trainable params: 1,154\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 8771 samples, validate on 2193 samples\n",
      "Epoch 1/10\n",
      "8771/8771 [==============================] - 1s 75us/step - loss: 10.4632 - acc: 0.3473 - val_loss: 10.4602 - val_acc: 0.3475\n",
      "Epoch 2/10\n",
      "8771/8771 [==============================] - 1s 62us/step - loss: 10.4632 - acc: 0.3473 - val_loss: 10.4602 - val_acc: 0.3475\n",
      "Epoch 3/10\n",
      "8771/8771 [==============================] - 0s 56us/step - loss: 10.4632 - acc: 0.3473 - val_loss: 10.4602 - val_acc: 0.3475\n",
      "Epoch 4/10\n",
      "8771/8771 [==============================] - 0s 52us/step - loss: 10.4632 - acc: 0.3473 - val_loss: 10.4602 - val_acc: 0.3475\n",
      "Epoch 5/10\n",
      "8771/8771 [==============================] - 0s 54us/step - loss: 10.4632 - acc: 0.3473 - val_loss: 10.4602 - val_acc: 0.3475\n",
      "Epoch 6/10\n",
      "8771/8771 [==============================] - 1s 67us/step - loss: 10.4632 - acc: 0.3473 - val_loss: 10.4602 - val_acc: 0.3475\n",
      "Epoch 7/10\n",
      "8771/8771 [==============================] - 0s 57us/step - loss: 10.4632 - acc: 0.3473 - val_loss: 10.4602 - val_acc: 0.3475\n",
      "Epoch 8/10\n",
      "8771/8771 [==============================] - 0s 54us/step - loss: 10.4632 - acc: 0.3473 - val_loss: 10.4602 - val_acc: 0.3475\n",
      "Epoch 9/10\n",
      "8771/8771 [==============================] - 1s 67us/step - loss: 10.4632 - acc: 0.3473 - val_loss: 10.4602 - val_acc: 0.3475\n",
      "Epoch 10/10\n",
      "8771/8771 [==============================] - 0s 52us/step - loss: 10.4632 - acc: 0.3473 - val_loss: 10.4602 - val_acc: 0.3475\n",
      "Test score: 10.460224631275155\n",
      "Test accuracy: 0.3474692202870073\n",
      "[10.460224631275155, 0.3474692202870073]\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42, stratify = y)\n",
    "batch_size = 32\n",
    "nb_classes = 2\n",
    "nb_epoch = 10\n",
    "input_dim = 15\n",
    "\n",
    "# the data, shuffled and split between train and test sets\n",
    "\n",
    "X_train = X_train.astype('int64')\n",
    "X_test = X_test.astype('int64')\n",
    "print(X_train.shape[0], 'train samples')\n",
    "print(X_test.shape[0], 'test samples')\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "Y_train = np_utils.to_categorical(y_train, nb_classes)\n",
    "Y_test = np_utils.to_categorical(y_test, nb_classes)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(64, input_dim=input_dim, activation='relu'))\n",
    "model.add(Dense(nb_classes, input_dim=64, activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# compile the model\n",
    "model.compile(optimizer='sgd', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "history = model.fit(X_train, Y_train,\n",
    "                    batch_size=batch_size, epochs=nb_epoch,\n",
    "                    verbose=1, validation_data=(X_test, Y_test))\n",
    "score = model.evaluate(X_test, Y_test, verbose=0)\n",
    "\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try smaller batches with tanh activation function in first layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8771 train samples\n",
      "2193 test samples\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_8 (Dense)              (None, 64)                1024      \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 1,154\n",
      "Trainable params: 1,154\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Train on 8771 samples, validate on 2193 samples\n",
      "Epoch 1/10\n",
      "8771/8771 [==============================] - 1s 134us/step - loss: 0.6520 - acc: 0.6511 - val_loss: 0.6850 - val_acc: 0.6525\n",
      "Epoch 2/10\n",
      "8771/8771 [==============================] - 1s 101us/step - loss: 0.6523 - acc: 0.6520 - val_loss: 0.6949 - val_acc: 0.3475\n",
      "Epoch 3/10\n",
      "8771/8771 [==============================] - 1s 100us/step - loss: 0.6515 - acc: 0.6514 - val_loss: 0.6520 - val_acc: 0.6525\n",
      "Epoch 4/10\n",
      "8771/8771 [==============================] - 1s 104us/step - loss: 0.6520 - acc: 0.6527 - val_loss: 0.6705 - val_acc: 0.6525\n",
      "Epoch 5/10\n",
      "8771/8771 [==============================] - 1s 108us/step - loss: 0.6522 - acc: 0.6516 - val_loss: 0.6515 - val_acc: 0.6525\n",
      "Epoch 6/10\n",
      "8771/8771 [==============================] - 1s 123us/step - loss: 0.6514 - acc: 0.6509 - val_loss: 0.6462 - val_acc: 0.6525\n",
      "Epoch 7/10\n",
      "8771/8771 [==============================] - 1s 108us/step - loss: 0.6514 - acc: 0.6527 - val_loss: 0.6721 - val_acc: 0.6525\n",
      "Epoch 8/10\n",
      "8771/8771 [==============================] - 1s 135us/step - loss: 0.6517 - acc: 0.6518 - val_loss: 0.6470 - val_acc: 0.6525\n",
      "Epoch 9/10\n",
      "8771/8771 [==============================] - 1s 116us/step - loss: 0.6505 - acc: 0.6527 - val_loss: 0.6478 - val_acc: 0.6525\n",
      "Epoch 10/10\n",
      "8771/8771 [==============================] - 1s 105us/step - loss: 0.6518 - acc: 0.6527 - val_loss: 0.6516 - val_acc: 0.6525\n",
      "Test score: 0.6515959793717906\n",
      "Test accuracy: 0.6525307799440184\n",
      "[0.6515959793717906, 0.6525307799440184]\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=42, stratify = y)\n",
    "batch_size = 16\n",
    "nb_classes = 2\n",
    "nb_epoch = 10\n",
    "input_dim = 15\n",
    "\n",
    "# the data, shuffled and split between train and test sets\n",
    "\n",
    "X_train = X_train.astype('int64')\n",
    "X_test = X_test.astype('int64')\n",
    "print(X_train.shape[0], 'train samples')\n",
    "print(X_test.shape[0], 'test samples')\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "Y_train = np_utils.to_categorical(y_train, nb_classes)\n",
    "Y_test = np_utils.to_categorical(y_test, nb_classes)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(64, input_dim=input_dim, activation='tanh'))\n",
    "model.add(Dense(nb_classes, input_dim=64, activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# compile the model\n",
    "model.compile(optimizer='sgd', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "history = model.fit(X_train, Y_train,\n",
    "                    batch_size=batch_size, epochs=nb_epoch,\n",
    "                    verbose=1, validation_data=(X_test, Y_test))\n",
    "score = model.evaluate(X_test, Y_test, verbose=0)\n",
    "\n",
    "print('Test score:', score[0])\n",
    "print('Test accuracy:', score[1])\n",
    "print(score)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
